# autochecker/llm_analyzer.py
import json
from typing import Dict

import google.genai as genai
from .repo_reader import RepoReader
from .github_client import GitHubClient


def analyze_repo(gemini_api_key: str, reader: RepoReader, client: GitHubClient) -> Dict:
    """
    –ê–Ω–∞–ª–∏–∑ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è —Å –ø–æ–º–æ—â—å—é Gemini.
    –û–±–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–¥ google-genai >=1.4: –∏—Å–ø–æ–ª—å–∑—É–µ–º Client().models.generate_content.
    """
    llm_client = genai.Client(api_key=gemini_api_key)

    # 1. –°–æ–±–∏—Ä–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    readme_content = reader.read_file("README.md") or "README.md –Ω–µ –Ω–∞–π–¥–µ–Ω."

    repo_info = client.get_repo_info()
    default_branch = repo_info.get('default_branch', 'main') if repo_info else 'main'

    commits = client.get_commits(branch=default_branch)
    commit_messages = "\n".join([c['commit']['message'] for c in commits]) if commits else "–ö–æ–º–º–∏—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã."

    repo_content = f"""
–°–æ–¥–µ—Ä–∂–∏–º–æ–µ README.md:
---
{readme_content}
---

–ò—Å—Ç–æ—Ä–∏—è –∫–æ–º–º–∏—Ç–æ–≤:
---
{commit_messages}
---
"""

    # 2. –§–æ—Ä–º—É–ª–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç
    prompt = f"""
–¢—ã ‚Äî –æ–ø—ã—Ç–Ω—ã–π –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—é, –ø—Ä–æ–≤–µ—Ä—è—é—â–∏–π —É—á–µ–±–Ω—ã–π –ø—Ä–æ–µ–∫—Ç.
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–∞–±–æ—Ç–µ —Å—Ç—É–¥–µ–Ω—Ç–∞:
{repo_content}

–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –¥–∞—Ç—å –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω—É—é –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å.
–û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON —Å–æ —Å–ª–µ–¥—É—é—â–∏–º–∏ –∫–ª—é—á–∞–º–∏:
- "verdict": –ö—Ä–∞—Ç–∫–∏–π –∏—Ç–æ–≥. –û–¥–Ω–æ –∏–∑: "excellent", "good", "satisfactory", "weak", "fail".
- "reasons": –°–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ–º –æ—Ü–µ–Ω–∫–∏. –ß—Ç–æ –±—ã–ª–æ —Ö–æ—Ä–æ—à–æ, –∞ —á–µ–≥–æ –Ω–µ —Ö–≤–∞—Ç–∏–ª–æ?
- "quotes": –°–ø–∏—Å–æ–∫ –∏–∑ 2-3 –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —Ü–∏—Ç–∞—Ç –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ (README –∏–ª–∏ –∫–æ–º–º–∏—Ç—ã), –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞—é—Ç —Ç–≤–æ–∏ –≤—ã–≤–æ–¥—ã.

–ü—Ä–∏–º–µ—Ä –æ—Ç–≤–µ—Ç–∞:
{{
  "verdict": "good",
  "reasons": [
    "–•–æ—Ä–æ—à–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ README —Ñ–∞–π–ª–∞.",
    "–ù–µ –≤—Å–µ –∫–æ–º–º–∏—Ç—ã —Å–ª–µ–¥—É—é—Ç –ø—Ä–∏–Ω—è—Ç–æ–º—É —Å—Ç–∏–ª—é."
  ],
  "quotes": [
    "feat: add user authentication",
    "Initial commit"
  ]
}}

–¢–µ–ø–µ—Ä—å, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å —Å–≤–æ–π –∞–Ω–∞–ª–∏–∑ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON.
"""

    # 3. –í—ã–∑—ã–≤–∞–µ–º –º–æ–¥–µ–ª—å –∏ –ø–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    try:
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        try:
            available_models = list(llm_client.models.list())
            model_names = [m.name.split('/')[-1] for m in available_models if hasattr(m, 'name')]
            print(f"üìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏: {', '.join(model_names[:5])}...")
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é –º–æ–¥–µ–ª—å –∏–∑ —Å–ø–∏—Å–∫–∞
            if model_names:
                candidates = model_names[:3] + [
                    "gemini-1.5-flash",
                    "gemini-1.5-pro",
                    "gemini-1.5-flash-001",
                    "gemini-1.5-pro-001",
                ]
            else:
                candidates = [
                    "gemini-1.5-flash",
                    "gemini-1.5-pro",
                    "gemini-1.5-flash-001",
                    "gemini-1.5-pro-001",
                ]
        except Exception as list_error:
            # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –Ω–∞–±–æ—Ä
            print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π: {list_error}")
            candidates = [
                "gemini-1.5-flash",
                "gemini-1.5-pro",
                "gemini-1.5-flash-001",
                "gemini-1.5-pro-001",
            ]
        
        last_error = None
        for model_name in candidates:
            try:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≤—ã–∑–æ–≤–∞
                response = llm_client.models.generate_content(
                    model=model_name,
                    contents=prompt
                )
                
                # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞
                text = response.text
                
                cleaned_json = (
                    text.strip()
                    .replace("```json", "")
                    .replace("```", "")
                    .strip()
                )
                analysis = json.loads(cleaned_json)
                print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –º–æ–¥–µ–ª—å: {model_name}")
                return analysis
            except Exception as model_error:
                last_error = model_error
                error_msg = str(model_error)
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–æ–ª—å–∫–æ –æ—à–∏–±–∫–∏ 404, –¥—Ä—É–≥–∏–µ –æ—à–∏–±–∫–∏ –º–æ–≥—É—Ç –±—ã—Ç—å –≤–∞–∂–Ω—ã–º–∏
                if "404" not in error_msg and "NOT_FOUND" not in error_msg:
                    print(f"üö® –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ —Å –º–æ–¥–µ–ª—å—é {model_name}: {error_msg[:150]}")
                    raise
                continue

        raise last_error or RuntimeError("LLM call failed")
    except Exception as e:
        print(f"üö® –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ Gemini API –∏–ª–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ JSON: {e}")
        return {
            "verdict": "–∞–Ω–∞–ª–∏–∑_–ø—Ä–æ–≤–∞–ª–µ–Ω",
            "reasons": [f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ: {e}"],
            "quotes": [],
        }
